# Denoising-and-Stacked-Autoencoders
An autoencoder is an unsupervised neural network where the output learned is the same as the input. It serves an excellent feature extractor. We have implemented denoising autoencoder with a single hidden layer. Images which were corrupted with Gaussian noise with variance v and mean 0 were trained using an autoencoder. The model was then used to analyze the denoising capabilities of the network. The network was able to handle noise up to ’v’ very well and it wasn’t able to reproduce the images when the image was corrupted with noise more than ’v’. Stacked autoencoders were built with three hidden layers and it gave the best accuracy of 72.8 when 10 samples per class were used for training compared to several other machine learning classiﬁers such as Logistic Regression, Gaussian Naive Bayes, Decision Trees, Random Forests, KNN, SVM, Bernoulli Naive Bayes, Multinomial Naive Bayes. Logistic regression gave the second best accuracy of 71.42 with lbfgs solver and random forestsgavethethirdbestaccuracywith65.06.Similarly,when just a single sample per class was used for training, stacked autoencoders performed exceptionally well with an accuracy of 53.33 which was then followed by Bernoulli Naive Bayes which gave an accuracy of 52.

![Test Image 4](https://github.com/tograh/testrepository/3DTest.png)
